{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c00f354c-b061-4e90-883a-0d3cdf10de55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1dd95d96-bf4c-476f-96dd-45de3a4640d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7cd306c-aa4f-4ac6-83a0-54fefa586e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "base_dir = '/content/drive/MyDrive/Pose Estimation/data/Taken'\n",
    "\n",
    "# Function to retrieve all image paths from a directory\n",
    "def get_image_paths(directory):\n",
    "    # List to store paths\n",
    "    image_paths = []\n",
    "    # os.walk goes through all subdirectories\n",
    "    for subdir, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            # Check for jpeg files\n",
    "            if file.endswith(\".jpeg\") or file.endswith(\".jpg\"):\n",
    "                # Construct full file path\n",
    "                full_path = os.path.join(subdir, file)\n",
    "                image_paths.append(full_path)\n",
    "    return image_paths\n",
    "\n",
    "# Get image paths for 'sweep' and 'pull' directories\n",
    "sweep_images = get_image_paths(os.path.join(base_dir, 'sweep'))\n",
    "pull_images = get_image_paths(os.path.join(base_dir, 'pull'))\n",
    "\n",
    "# Combine all image paths\n",
    "all_image_paths = sweep_images + pull_images\n",
    "\n",
    "images_to_remove = ['5.jpeg', '3pull.jpeg']\n",
    "\n",
    "# Filter out specific images\n",
    "filtered_image_paths = [path for path in all_image_paths if not any(img in path for img in images_to_remove)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f2eb5c1-6616-40bc-b2e5-91eb0068d6f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image_paths\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Get image paths for 'sweep' and 'pull' directories\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m sweep_images_t \u001b[38;5;241m=\u001b[39m get_image_paths(\u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_dir2, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSweep\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     21\u001b[0m pull_images_t \u001b[38;5;241m=\u001b[39m get_image_paths(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_dir2, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPull\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Combine all image paths\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# Training 2\n",
    "\n",
    "base_dir2 = '/content/drive/MyDrive/Pose Estimation/data/Manual'\n",
    "\n",
    "# Function to retrieve all image paths from a directory\n",
    "def get_image_paths(directory):\n",
    "    # List to store paths\n",
    "    image_paths = []\n",
    "    # os.walk goes through all subdirectories\n",
    "    for subdir, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            # Check for jpeg files\n",
    "            if file.endswith(\".jpeg\") or file.endswith(\".jpg\"):\n",
    "                # Construct full file path\n",
    "                full_path = os.path.join(subdir, file)\n",
    "                image_paths.append(full_path)\n",
    "    return image_paths\n",
    "\n",
    "# Get image paths for 'sweep' and 'pull' directories\n",
    "sweep_images_t = get_image_paths(os.path.join(base_dir2, 'Sweep'))\n",
    "pull_images_t = get_image_paths(os.path.join(base_dir2, 'Pull'))\n",
    "\n",
    "# Combine all image paths\n",
    "all_image_paths_t = sweep_images_t + pull_images_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7b5a4fb-6ede-4ed3-9ddc-37398a56835b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m v_image_paths \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Walk through the directory\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m root, dirs, files \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mwalk(base_dir3):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;66;03m# Check for specific file extensions if needed (e.g., '.jpg', '.png')\u001b[39;00m\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     12\u001b[0m             \u001b[38;5;66;03m# Construct the full path to the file\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "#Testing\n",
    "\n",
    "base_dir3 = '/content/drive/MyDrive/Pose Estimation/data/Test'\n",
    "\n",
    "v_image_paths = []\n",
    "\n",
    "# Walk through the directory\n",
    "for root, dirs, files in os.walk(base_dir3):\n",
    "    for file in files:\n",
    "        # Check for specific file extensions if needed (e.g., '.jpg', '.png')\n",
    "        if file.endswith(\".jpg\") or file.endswith(\".jpeg\"):\n",
    "            # Construct the full path to the file\n",
    "            path = os.path.join(root, file)\n",
    "            v_image_paths.append(path)\n",
    "\n",
    "# Now image_paths contains all the paths to the images in your validation dataset\n",
    "print(v_image_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "418a2524-930d-42b3-8b34-9e07cbf82903",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hub' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mhub\u001b[49m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://tfhub.dev/google/movenet/singlepose/lightning/4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m movenet \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39msignatures[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserving_default\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hub' is not defined"
     ]
    }
   ],
   "source": [
    "model = hub.load('https://tfhub.dev/google/movenet/singlepose/lightning/4')\n",
    "movenet = model.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccde9a6f-00b9-463a-a13a-0b945467a7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path= '/content/drive/MyDrive/Pose Estimation/data/Taken/pull/6pull.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdb8411c-3148-4889-ab64-225410b084be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw too\n",
    "\n",
    "def draw_pose(image, keypoints):\n",
    "    # Define the connections between keypoints to form a pose\n",
    "    connections = [\n",
    "        [0, 1], [0, 2], [1, 3], [2, 4],  # Upper body\n",
    "        [5, 6], [5, 7], [7, 9], [6, 8],  # Lower body\n",
    "        [8, 10], [5, 11], [6, 12], [11, 12],  # Arms\n",
    "        [11, 13], [12, 14], [13, 15], [14, 16]  # Forearms\n",
    "    ]\n",
    "\n",
    "    # Convert image from float to uint8\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.uint8)\n",
    "    image = tf.squeeze(image)  # Remove batch dimension\n",
    "\n",
    "    # Plot the image\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image)\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Plot keypoints\n",
    "    for keypoint in keypoints[0][0]:\n",
    "        y, x, confidence = keypoint\n",
    "        if confidence > 0.1:  #\n",
    "            plt.plot(x * width, y * height, 'ro', markersize=5)\n",
    "\n",
    "    # Connect keypoints to visualize the pose\n",
    "    for connection in connections:\n",
    "        start_keypoint = keypoints[0][0][connection[0]]\n",
    "        end_keypoint = keypoints[0][0][connection[1]]\n",
    "        start_point = (start_keypoint[1] * width, start_keypoint[0] * height)  # Flip x and y\n",
    "        end_point = (end_keypoint[1] * width, end_keypoint[0] * height)  # Flip x and y\n",
    "        plt.plot([start_point[0], end_point[0]], [start_point[1], end_point[1]], 'g-', linewidth=2)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def run_pose_estimation(image_path):\n",
    "    # Load and prepare the image\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)  # Decode the image\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)  # Convert to float values in [0, 1]\n",
    "\n",
    "    # Resize the image to match the expected input size of MoveNet\n",
    "    img = tf.image.resize(img, (192, 192))\n",
    "\n",
    "    # Convert the image to int32 data type\n",
    "    img = tf.cast(img * 255, dtype=tf.int32)\n",
    "\n",
    "    # Add a batch dimension\n",
    "    img = tf.expand_dims(img, axis=0)\n",
    "\n",
    "    # Run model inference\n",
    "    results = movenet(input=img)  # Pass the image as 'input' argument\n",
    "    keypoints = results['output_0'].numpy()\n",
    "\n",
    "\n",
    "    # Draw pose on the image\n",
    "    draw_pose(img, keypoints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b31f8af-d08e-4fff-9eaa-0564b9a872b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrun_pose_estimation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 40\u001b[0m, in \u001b[0;36mrun_pose_estimation\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_pose_estimation\u001b[39m(image_path):\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Load and prepare the image\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mread_file(image_path)\n\u001b[0;32m     41\u001b[0m     img \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mdecode_jpeg(img, channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)  \u001b[38;5;66;03m# Decode the image\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     img \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mconvert_image_dtype(img, tf\u001b[38;5;241m.\u001b[39mfloat32)  \u001b[38;5;66;03m# Convert to float values in [0, 1]\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "run_pose_estimation(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8057d57-d820-45bd-916c-3bfb3e2c8d58",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hub' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the MoveNet \"lightning\" model from TensorFlow Hub\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mhub\u001b[49m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://tfhub.dev/google/movenet/singlepose/lightning/4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m movenet \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39msignatures[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserving_default\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Function to extract keypoints from an image\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hub' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the MoveNet \"lightning\" model from TensorFlow Hub\n",
    "model = hub.load('https://tfhub.dev/google/movenet/singlepose/lightning/4')\n",
    "movenet = model.signatures['serving_default']\n",
    "\n",
    "# Function to extract keypoints from an image\n",
    "def extract_keypoints(image_path):\n",
    "    # Load and prepare the image\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)  # Decode the image\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)  # Convert to float values in [0, 1]\n",
    "\n",
    "    # Resize the image to match the expected input size of MoveNet\n",
    "    img = tf.image.resize(img, (192, 192))\n",
    "\n",
    "    # Convert the image to int32 data type\n",
    "    img = tf.cast(img * 255, dtype=tf.int32)\n",
    "\n",
    "    # Add a batch dimension\n",
    "    img = tf.expand_dims(img, axis=0)\n",
    "\n",
    "    # Run model inference\n",
    "    results = movenet(input=img)  # Pass the image as 'input' argument\n",
    "    keypoints = results['output_0'].numpy()\n",
    "\n",
    "    # Flatten the keypoints array\n",
    "    keypoints_flat = keypoints.flatten()\n",
    "\n",
    "    return keypoints_flat\n",
    "\n",
    "image_paths_pull = pull_images_t + pull_images\n",
    "image_paths_sweep = sweep_images_t + sweep_images\n",
    "\n",
    "\n",
    "# Extract keypoints from labeled images\n",
    "X_pull = np.array([extract_keypoints(image_path) for image_path in image_paths_pull])\n",
    "X_sweep = np.array([extract_keypoints(image_path) for image_path in image_paths_sweep])\n",
    "\n",
    "# Create labels for pull shots (class 0) and sweep shots (class 1)\n",
    "y_pull = np.zeros(len(X_pull))\n",
    "y_sweep = np.ones(len(X_sweep))\n",
    "\n",
    "# Concatenate feature matrices and labels\n",
    "X = np.concatenate((X_pull, X_sweep), axis=0)\n",
    "y = np.concatenate((y_pull, y_sweep), axis=0)\n",
    "\n",
    "X_train = np.concatenate((X_pull, X_sweep), axis=0)\n",
    "y_train = np.concatenate((y_pull, y_sweep), axis=0)\n",
    "\n",
    "# Train classifier\n",
    "#model = LogisticRegression()\n",
    "#model = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "#model = LinearSVC(C=1.0, max_iter=10000)\n",
    "#model = MLPClassifier(tol=1e-6,activation='relu',hidden_layer_sizes=(30,4), max_iter=10000, alpha=1e-4,solver='sgd', verbose=10, random_state=1,learning_rate_init=.1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6324bbf8-f776-415c-978b-329d54010e5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load test data\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m X_test \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39marray([extract_keypoints(image_path) \u001b[38;5;28;01mfor\u001b[39;00m image_path \u001b[38;5;129;01min\u001b[39;00m v_image_paths])\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Predict on test data\u001b[39;00m\n\u001b[0;32m      6\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "\n",
    "X_test = np.array([extract_keypoints(image_path) for image_path in v_image_paths])\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(4, 8))\n",
    "for i, (image_path, prediction) in enumerate(zip(v_image_paths, y_pred)):\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert from BGR to RGB\n",
    "\n",
    "    # Plot image\n",
    "    plt.subplot(len(v_image_paths), 1, i + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Predicted class: {'pull shot' if prediction == 0 else 'sweep shot'}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46ae0c4b-c4e9-438c-b1ea-108a17fa299d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for test images:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredictions for test images:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_path, prediction \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(v_image_paths, \u001b[43my_pred\u001b[49m):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Predicted class: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpull shot\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mprediction\u001b[38;5;250m \u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m0\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msweep shot\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Predictions for test images:\")\n",
    "for image_path, prediction in zip(v_image_paths, y_pred):\n",
    "    print(f\"Image: {image_path}, Predicted class: {'pull shot' if prediction == 0 else 'sweep shot'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199e8518-70c1-4a6f-a7d2-8df290411535",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
